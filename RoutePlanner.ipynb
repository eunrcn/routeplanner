{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for state S3 and action S8: -0.037500000000000006\n",
      "Rewards Table:\n",
      "State -> [Action1, Action2, ..., ActionN] -> [Reward1, Reward2, ..., RewardN]\n",
      "S1 -> ['S2', 'S6', 'S10'] -> {'S2': -0.0433, 'S6': -0.0295, 'S10': -0.0363}\n",
      "S2 -> ['S1', 'S6', 'S7', 'S3', 'S11'] -> {'S1': -0.0433, 'S6': -0.0271, 'S7': -0.059399999999999994, 'S3': -0.0416, 'S11': -0.048}\n",
      "S3 -> ['S2', 'S7', 'S8', 'S4'] -> {'S2': -0.0416, 'S7': -0.0495, 'S8': -0.037500000000000006, 'S4': -0.0375}\n",
      "S4 -> ['S3', 'S8', 'S9', 'S5'] -> {'S3': -0.0375, 'S8': -0.051000000000000004, 'S9': -0.057800000000000004, 'S5': -0.0519}\n",
      "S5 -> ['S4', 'S9', 'S14'] -> {'S4': -0.0519, 'S9': -0.060300000000000006, 'S14': -0.0852}\n",
      "S6 -> ['S1', 'S2', 'S10', 'S11', 'S7'] -> {'S1': -0.0295, 'S2': -0.0271, 'S10': -0.026099999999999998, 'S11': -0.034199999999999994, 'S7': -0.039}\n",
      "S7 -> ['S2', 'S3', 'S8', 'S12', 'S11', 'S6'] -> {'S2': -0.059399999999999994, 'S3': -0.0495, 'S8': -0.0365, 'S12': -0.0435, 'S11': -0.033299999999999996, 'S6': -0.039}\n",
      "S8 -> ['S3', 'S4', 'S7', 'S9', 'S12', 'S13'] -> {'S3': -0.037500000000000006, 'S4': -0.051000000000000004, 'S7': -0.0365, 'S9': -0.056799999999999996, 'S12': -0.052000000000000005, 'S13': -0.046200000000000005}\n",
      "S9 -> ['S4', 'S5', 'S8', 'S13', 'S14'] -> {'S4': -0.057800000000000004, 'S5': -0.060300000000000006, 'S8': -0.056799999999999996, 'S13': -0.0505, 'S14': -0.0693}\n",
      "S10 -> ['S1', 'S6', 'S11'] -> {'S1': -0.0363, 'S6': -0.026099999999999998, 'S11': -0.022}\n",
      "S11 -> ['S10', 'S6', 'S2', 'S7', 'S12'] -> {'S10': -0.022, 'S6': -0.034199999999999994, 'S2': -0.048, 'S7': -0.033299999999999996, 'S12': -0.0298}\n",
      "S12 -> ['S11', 'S7', 'S8', 'S13'] -> {'S11': -0.0298, 'S7': -0.0435, 'S8': -0.052000000000000005, 'S13': -0.047400000000000005}\n",
      "S13 -> ['S12', 'S8', 'S9', 'S14'] -> {'S12': -0.047400000000000005, 'S8': -0.046200000000000005, 'S9': -0.0505, 'S14': -0.06960000000000001}\n",
      "S14 -> ['S13', 'S9', 'S5'] -> {'S13': -0.06960000000000001, 'S9': -0.0693, 'S5': -0.0852}\n",
      "Transition Probabilities Table:\n",
      "State S1, Action S2 -> Transition Probabilities: {'S2': 0.11536309301730212, 'S3': 0.026028192877177465, 'S4': 0.13202168886647736, 'S5': 0.02791051647104934, 'S6': 0.1379438650677701, 'S7': 0.009213938500366623, 'S8': 0.04933922126147314, 'S9': 0.15898305242777896, 'S10': 0.13958070996335026, 'S11': 0.03736354108479312, 'S12': 0.009845906886041169, 'S13': 0.02504194333519761, 'S14': 0.1313643302412226}\n",
      "State S1, Action S6 -> Transition Probabilities: {'S2': 0.07643735521697483, 'S3': 0.08402847926027288, 'S4': 0.04965762183037832, 'S5': 0.09501613699816941, 'S6': 0.03563757346797783, 'S7': 0.03896141139835453, 'S8': 0.08157729524339687, 'S9': 0.10629819042044109, 'S10': 0.1283385631338599, 'S11': 0.019672019333576988, 'S12': 0.11973515532051439, 'S13': 0.045444292065582786, 'S14': 0.1191959063105002}\n",
      "State S1, Action S10 -> Transition Probabilities: {'S2': 0.011676214530845481, 'S3': 0.008085434696966943, 'S4': 0.11263078160101109, 'S5': 0.13959449132518656, 'S6': 0.0006314928823916969, 'S7': 0.06348975583637807, 'S8': 0.13470106000754878, 'S9': 0.0022308546450653583, 'S10': 0.0598623425416004, 'S11': 0.13451806457478224, 'S12': 0.13439837128644447, 'S13': 0.055912714501005635, 'S14': 0.14226842157077335}\n",
      "State S2, Action S1 -> Transition Probabilities: {'S1': 0.07825039990276084, 'S3': 0.021515127044160844, 'S4': 0.09353222225536642, 'S5': 0.13234716071197936, 'S6': 0.08421411627282555, 'S7': 0.03359369532528723, 'S8': 0.13925101460727252, 'S9': 0.02783050609441372, 'S10': 0.12999196035379165, 'S11': 0.019362331480333894, 'S12': 0.10520892386692138, 'S13': 0.03320521923466855, 'S14': 0.10169732285021799}\n",
      "State S2, Action S6 -> Transition Probabilities: {'S1': 0.05710360552421673, 'S3': 0.09930774138627405, 'S4': 0.0865493139769932, 'S5': 0.10535542282893091, 'S6': 0.09345355123710634, 'S7': 0.05618185533804265, 'S8': 0.08731857378216291, 'S9': 0.10322496413720293, 'S10': 0.06553268645090626, 'S11': 0.06741223640010394, 'S12': 0.09387659862259909, 'S13': 0.07077697636471392, 'S14': 0.013906473950746867}\n",
      "State S2, Action S7 -> Transition Probabilities: {'S1': 0.08569104193348295, 'S3': 0.046316761208062524, 'S4': 0.0753142614918229, 'S5': 0.06065795902726368, 'S6': 0.11939210220365698, 'S7': 0.1266175650264906, 'S8': 0.025544719525493403, 'S9': 0.12724995585813612, 'S10': 0.07895560573899386, 'S11': 0.10401641558318635, 'S12': 0.08051325920459962, 'S13': 0.02596316466456618, 'S14': 0.04376718853424498}\n",
      "State S2, Action S3 -> Transition Probabilities: {'S1': 0.12786935340772232, 'S3': 0.07997623621942737, 'S4': 0.1319438058792665, 'S5': 0.056450779653404205, 'S6': 0.004320313381495213, 'S7': 0.06185165555569871, 'S8': 0.04674093713114914, 'S9': 0.0941046804130568, 'S10': 0.12949625595881661, 'S11': 0.0040073891945884505, 'S12': 0.14160136667926515, 'S13': 0.03147081114111635, 'S14': 0.09016641538499327}\n",
      "State S2, Action S11 -> Transition Probabilities: {'S1': 0.1599683607074439, 'S3': 0.03896322893028467, 'S4': 0.10827389451078867, 'S5': 0.0502847982214738, 'S6': 0.1302589989076561, 'S7': 0.03419468737711113, 'S8': 0.040160443579367315, 'S9': 0.15245698037286168, 'S10': 0.021026599349889253, 'S11': 0.07954911667729622, 'S12': 0.05831857019934645, 'S13': 0.09625482634933018, 'S14': 0.030289494817150816}\n",
      "State S3, Action S2 -> Transition Probabilities: {'S1': 0.07536410239319512, 'S2': 0.008028998890026616, 'S4': 0.1088894913094208, 'S5': 0.008679627434268396, 'S6': 0.03593055453677124, 'S7': 0.07503272616055645, 'S8': 0.12383971807950703, 'S9': 0.018217070924046813, 'S10': 0.06979750633821767, 'S11': 0.12021763684597503, 'S12': 0.08646948474480938, 'S13': 0.13995164224640158, 'S14': 0.12958144009680408}\n",
      "State S3, Action S7 -> Transition Probabilities: {'S1': 0.019041424855159677, 'S2': 0.0947119952423955, 'S4': 0.053368394900272294, 'S5': 0.11228835703938429, 'S6': 0.06856488864374602, 'S7': 0.1327364065044173, 'S8': 0.021756772146817118, 'S9': 0.0882104596858438, 'S10': 0.03531786981506813, 'S11': 0.022350961887267533, 'S12': 0.10853049801649073, 'S13': 0.11401926564171726, 'S14': 0.1291027056214202}\n",
      "State S3, Action S8 -> Transition Probabilities: {'S1': 0.0582802564486529, 'S2': 0.09392451622720707, 'S4': 0.11186796735117992, 'S5': 0.11949951788877551, 'S6': 0.058513034369867024, 'S7': 0.05042583912467496, 'S8': 0.1033604382652331, 'S9': 0.10642905587316001, 'S10': 0.030296377702447856, 'S11': 0.11427248353498262, 'S12': 0.05401941842053183, 'S13': 0.09828121955124758, 'S14': 0.0008298752420396825}\n",
      "State S3, Action S4 -> Transition Probabilities: {'S1': 0.055541677108794804, 'S2': 0.0012025637789904748, 'S4': 0.1614555969199937, 'S5': 0.15000192580587854, 'S6': 0.023881269706802457, 'S7': 0.07146210148083097, 'S8': 0.11630311596005043, 'S9': 0.018044497065418698, 'S10': 0.05981231009684666, 'S11': 0.16543535777556914, 'S12': 0.06821835042519611, 'S13': 0.019176896073311862, 'S14': 0.08946433780231612}\n",
      "State S4, Action S3 -> Transition Probabilities: {'S1': 0.043852873975287546, 'S2': 0.17580818473946508, 'S3': 0.026116206061279748, 'S5': 0.006685691091254857, 'S6': 0.057042372518423035, 'S7': 0.1467505967254403, 'S8': 0.14458937969093755, 'S9': 0.16540992312076785, 'S10': 0.01701832280726037, 'S11': 0.0692584450386498, 'S12': 0.047645675567229574, 'S13': 0.016459775153870832, 'S14': 0.08336255351013376}\n",
      "State S4, Action S8 -> Transition Probabilities: {'S1': 0.002399451478285551, 'S2': 0.025746688170664788, 'S3': 0.009928905721062, 'S5': 0.13912978615762697, 'S6': 0.06855954454239152, 'S7': 0.0639019278658668, 'S8': 0.02034788895318453, 'S9': 0.10715608799919021, 'S10': 0.12203418006043708, 'S11': 0.11432869599136627, 'S12': 0.07941749423393936, 'S13': 0.1456764699033295, 'S14': 0.10137287892265527}\n",
      "State S4, Action S9 -> Transition Probabilities: {'S1': 0.1298161586516281, 'S2': 0.09192037115912616, 'S3': 0.12000187596320686, 'S5': 0.03664417026298018, 'S6': 0.07265804587324946, 'S7': 0.11585123232042761, 'S8': 0.12005125350065728, 'S9': 0.09806529484179705, 'S10': 0.06134126333096327, 'S11': 0.06275594838097653, 'S12': 0.01602066578256427, 'S13': 0.02536425216210823, 'S14': 0.04950946777031497}\n",
      "State S4, Action S5 -> Transition Probabilities: {'S1': 0.0777283969865455, 'S2': 0.10600783375089783, 'S3': 0.06575483484084511, 'S5': 0.07084599949267639, 'S6': 0.1056368799007861, 'S7': 0.06682108166549951, 'S8': 0.08490858774259918, 'S9': 0.059654977297629065, 'S10': 0.1016899655364208, 'S11': 0.03126838215921484, 'S12': 0.09745848456035432, 'S13': 0.10446785689560911, 'S14': 0.027756719170922393}\n",
      "State S5, Action S4 -> Transition Probabilities: {'S1': 0.018318077537855564, 'S2': 0.13409991313737074, 'S3': 0.0008769295916120563, 'S4': 0.12494036346107094, 'S6': 0.01426715861292452, 'S7': 0.10094996017515515, 'S8': 0.13359981978198063, 'S9': 0.04157360985573448, 'S10': 0.013356930207508671, 'S11': 0.14289977603489584, 'S12': 0.015859036403131667, 'S13': 0.1592681910649789, 'S14': 0.09999023413578076}\n",
      "State S5, Action S9 -> Transition Probabilities: {'S1': 0.018790839404543666, 'S2': 0.04097494600320474, 'S3': 0.13004714688898428, 'S4': 0.13052939241880981, 'S6': 0.052038846947884354, 'S7': 0.07140270281572789, 'S8': 0.11780929689728291, 'S9': 0.012860376857888633, 'S10': 0.11244564277283367, 'S11': 0.12345691568079219, 'S12': 0.07778674374993592, 'S13': 0.03559756341294921, 'S14': 0.07625958614916267}\n",
      "State S5, Action S14 -> Transition Probabilities: {'S1': 0.15345806550693805, 'S2': 0.11821897776146632, 'S3': 0.1487268739714415, 'S4': 0.10051187742520631, 'S6': 0.05727324702556285, 'S7': 0.029747457294953625, 'S8': 0.07174756023849545, 'S9': 0.059470750852648385, 'S10': 0.046510178095665475, 'S11': 0.05717894901292272, 'S12': 0.12876658002187244, 'S13': 0.018058955720087522, 'S14': 0.010330527072739449}\n",
      "State S6, Action S1 -> Transition Probabilities: {'S1': 0.02225831236825247, 'S2': 0.035810714617164334, 'S3': 0.09077668008535417, 'S4': 0.08739961157358676, 'S5': 0.1165084691694145, 'S7': 0.0440152321864642, 'S8': 0.12822507485837167, 'S9': 0.07544180737134035, 'S10': 0.10292444174094056, 'S11': 0.039888426863673554, 'S12': 0.09758865972607511, 'S13': 0.11236715132713608, 'S14': 0.046795418112226324}\n",
      "State S6, Action S2 -> Transition Probabilities: {'S1': 0.044600941527376044, 'S2': 0.06349773053813147, 'S3': 0.1655235719320567, 'S4': 0.006537072676283558, 'S5': 0.11966825146429183, 'S7': 0.08082731973643963, 'S8': 0.08169369214935657, 'S9': 0.08867053652771395, 'S10': 0.045056072176868446, 'S11': 0.02203202729109028, 'S12': 0.070237062287765, 'S13': 0.01872201269856935, 'S14': 0.19293370899405718}\n",
      "State S6, Action S10 -> Transition Probabilities: {'S1': 0.10423033531732837, 'S2': 0.05217073183711989, 'S3': 0.09440114094507239, 'S4': 0.07233799477979377, 'S5': 0.05325158041863421, 'S7': 0.11261973131086203, 'S8': 0.08677793540429667, 'S9': 0.06736011407900346, 'S10': 0.05700621087541116, 'S11': 0.10388272170247118, 'S12': 0.09619112424408632, 'S13': 0.010875665524939225, 'S14': 0.08889471356098134}\n",
      "State S6, Action S11 -> Transition Probabilities: {'S1': 0.1199868722353337, 'S2': 0.07719495081256628, 'S3': 0.04487145356208771, 'S4': 0.06547480056751165, 'S5': 0.13044672004143992, 'S7': 0.010299338494497693, 'S8': 0.02059425495733498, 'S9': 0.00044185676765753126, 'S10': 0.06950883035933576, 'S11': 0.15378656930721557, 'S12': 0.08057547054866077, 'S13': 0.15544572560903933, 'S14': 0.07137315673731917}\n",
      "State S6, Action S7 -> Transition Probabilities: {'S1': 0.022355873157408834, 'S2': 0.14648570252410797, 'S3': 0.14713919991627292, 'S4': 0.02299996974464498, 'S5': 0.08094857500506543, 'S7': 0.13172237886810378, 'S8': 0.11150527684478818, 'S9': 0.02102216291272732, 'S10': 0.06529818625758098, 'S11': 0.08223269073469187, 'S12': 0.024466950770662493, 'S13': 0.05453999788981439, 'S14': 0.08928303537413092}\n",
      "State S7, Action S2 -> Transition Probabilities: {'S1': 0.0050900343844045145, 'S2': 0.13649774668222356, 'S3': 0.022352687381973768, 'S4': 0.03001485729943428, 'S5': 0.041159414062207696, 'S6': 0.017546884566117263, 'S8': 0.15805835657192785, 'S9': 0.09947417075652737, 'S10': 0.12358226560215961, 'S11': 0.11902205867263517, 'S12': 0.025907076555204592, 'S13': 0.12930481500981622, 'S14': 0.0919896324553681}\n",
      "State S7, Action S3 -> Transition Probabilities: {'S1': 0.09541951709919017, 'S2': 0.17294593820515383, 'S3': 0.005052502926821751, 'S4': 0.01765495838932948, 'S5': 0.01097054784135587, 'S6': 0.12694060616305936, 'S8': 0.1493790400260806, 'S9': 0.06966244467072395, 'S10': 0.05522897051025359, 'S11': 0.06314373381254984, 'S12': 0.050957035036382145, 'S13': 0.14972532442749367, 'S14': 0.03291938089160546}\n",
      "State S7, Action S8 -> Transition Probabilities: {'S1': 0.15843670557048964, 'S2': 0.03773483324260816, 'S3': 0.08572223985871279, 'S4': 0.02206356730508413, 'S5': 0.03824666699451733, 'S6': 0.05752396662044836, 'S8': 0.07772004169914748, 'S9': 0.0478500557888671, 'S10': 0.1361000094845689, 'S11': 0.019640516830024813, 'S12': 0.1494707416021475, 'S13': 0.06260817321053884, 'S14': 0.10688248179284493}\n",
      "State S7, Action S12 -> Transition Probabilities: {'S1': 0.11777481465220359, 'S2': 0.01333489422726001, 'S3': 0.09769826808389537, 'S4': 0.08609815775393721, 'S5': 0.023637779889336175, 'S6': 0.011200986910061087, 'S8': 0.14522096259462078, 'S9': 0.03162336870458141, 'S10': 0.14342035041911258, 'S11': 0.16771053925927618, 'S12': 0.042193625813927986, 'S13': 0.09727923697204785, 'S14': 0.022807014719739928}\n",
      "State S7, Action S11 -> Transition Probabilities: {'S1': 0.04479527617333216, 'S2': 0.10865642948219675, 'S3': 0.0830424747835481, 'S4': 0.025769006702107283, 'S5': 0.12992117077633158, 'S6': 0.05458966404308249, 'S8': 0.013416135128810458, 'S9': 0.1423500238080062, 'S10': 0.08198626579091735, 'S11': 0.14325302999673103, 'S12': 0.1036006006626101, 'S13': 0.00027173254941682427, 'S14': 0.06834819010290966}\n",
      "State S7, Action S6 -> Transition Probabilities: {'S1': 0.04438214442986085, 'S2': 0.16295893296319253, 'S3': 0.006452095918647925, 'S4': 0.12351320792581676, 'S5': 0.13224606760793747, 'S6': 0.016611927292747113, 'S8': 0.10413624338449463, 'S9': 0.12345571092337247, 'S10': 0.004863017301164359, 'S11': 0.031222814364287588, 'S12': 0.005239726586907339, 'S13': 0.14290176909163316, 'S14': 0.1020163422099379}\n",
      "State S8, Action S3 -> Transition Probabilities: {'S1': 0.0868590695067935, 'S2': 0.07917411564189553, 'S3': 0.09468786451850959, 'S4': 0.08317981926635887, 'S5': 0.07074148625759394, 'S6': 0.0679559288577955, 'S7': 0.071030652933485, 'S9': 0.09026810349126956, 'S10': 0.006177551765182851, 'S11': 0.07557540402492059, 'S12': 0.08452743962866333, 'S13': 0.09804705975846989, 'S14': 0.09177550434906188}\n",
      "State S8, Action S4 -> Transition Probabilities: {'S1': 0.10964733776514393, 'S2': 0.15345115518323527, 'S3': 0.13685325660023612, 'S4': 0.0013354161363889807, 'S5': 0.1370545823996159, 'S6': 0.03910938095777526, 'S7': 0.01433361436163504, 'S9': 0.13429495076085846, 'S10': 0.0022045995502273895, 'S11': 0.009940719532940644, 'S12': 0.16204181841501575, 'S13': 0.08170670456296461, 'S14': 0.018026463773962415}\n",
      "State S8, Action S7 -> Transition Probabilities: {'S1': 0.1425724822039363, 'S2': 0.06781414031974428, 'S3': 0.11142813748732208, 'S4': 0.07344049703236621, 'S5': 0.005073970049494547, 'S6': 0.056484571243301175, 'S7': 0.04017520638949476, 'S9': 0.02734240111242679, 'S10': 0.10649758486836539, 'S11': 0.07103510084219807, 'S12': 0.17492195365267496, 'S13': 0.0321899578301525, 'S14': 0.09102399696852279}\n",
      "State S8, Action S9 -> Transition Probabilities: {'S1': 0.09560618489387546, 'S2': 0.0027591210839062463, 'S3': 0.13922767975066278, 'S4': 0.1063493513746017, 'S5': 0.06973126130236953, 'S6': 0.1351657439306237, 'S7': 0.0009228438689653389, 'S9': 0.1493257396685978, 'S10': 0.15659139621777543, 'S11': 0.05146773160472006, 'S12': 0.0338025048532537, 'S13': 0.04116844874584519, 'S14': 0.017881992704803167}\n",
      "State S8, Action S12 -> Transition Probabilities: {'S1': 0.1170874929699101, 'S2': 0.05398489132940164, 'S3': 0.025005521708998737, 'S4': 0.14051573417241478, 'S5': 0.15218173357632475, 'S6': 0.03936984613962537, 'S7': 0.02562993592793728, 'S9': 0.11614731332556287, 'S10': 0.005408073511791506, 'S11': 0.14757560559092975, 'S12': 0.04297707426464893, 'S13': 0.0930760264556426, 'S14': 0.04104075102681175}\n",
      "State S8, Action S13 -> Transition Probabilities: {'S1': 0.07744414010868006, 'S2': 0.08976964804324689, 'S3': 0.09003626070988238, 'S4': 0.03388985895036288, 'S5': 0.12312540581117849, 'S6': 0.05062325653531365, 'S7': 0.05500248702721906, 'S9': 0.10517964087523358, 'S10': 0.051232228665873424, 'S11': 0.03633351355745627, 'S12': 0.06332504670391116, 'S13': 0.10090785481639117, 'S14': 0.12313065819525097}\n",
      "State S9, Action S4 -> Transition Probabilities: {'S1': 0.08127447939486025, 'S2': 0.09914474504516609, 'S3': 0.03004180665355645, 'S4': 0.08690745665925594, 'S5': 0.08469661281019901, 'S6': 0.0845371172742339, 'S7': 0.10511471201493239, 'S8': 0.0951385485909069, 'S10': 0.1076098528443289, 'S11': 0.03937891924563571, 'S12': 0.02773233031563021, 'S13': 0.10161011939904906, 'S14': 0.05681329975224539}\n",
      "State S9, Action S5 -> Transition Probabilities: {'S1': 0.1164868744815525, 'S2': 0.01590310809601857, 'S3': 0.048235422515771224, 'S4': 0.09685173176580268, 'S5': 0.10879772777848763, 'S6': 0.02979483497549495, 'S7': 0.09412399851980424, 'S8': 0.06651410101106796, 'S10': 0.11389616697482216, 'S11': 0.08035921362919822, 'S12': 0.004449041674948627, 'S13': 0.10727701141059291, 'S14': 0.1173107671664384}\n",
      "State S9, Action S8 -> Transition Probabilities: {'S1': 0.015360432878099385, 'S2': 0.10840271771546371, 'S3': 0.06300484805530203, 'S4': 0.02222566718597898, 'S5': 0.07997867611087249, 'S6': 0.09277876067480066, 'S7': 0.09383275049679855, 'S8': 0.16378382708399833, 'S10': 0.008333109454888011, 'S11': 0.13544391468581105, 'S12': 0.12327432055426196, 'S13': 0.07964059092940619, 'S14': 0.013940384174318528}\n",
      "State S9, Action S13 -> Transition Probabilities: {'S1': 0.06713767815905951, 'S2': 0.1151567825112531, 'S3': 0.033686691994062296, 'S4': 0.11614269346260925, 'S5': 0.06323729733543956, 'S6': 0.08636900058506876, 'S7': 0.012889112027620645, 'S8': 0.07386909685130208, 'S10': 0.08321818539579082, 'S11': 0.14049552114065675, 'S12': 0.030476113651273836, 'S13': 0.09828468922333639, 'S14': 0.07903713766252694}\n",
      "State S9, Action S14 -> Transition Probabilities: {'S1': 0.022697834784612042, 'S2': 0.1376418125989667, 'S3': 0.11092847227509067, 'S4': 0.053702826130737534, 'S5': 0.02995742382219801, 'S6': 0.06857705669830226, 'S7': 0.05205632341465009, 'S8': 0.1521847781020723, 'S10': 0.10633798963861511, 'S11': 0.1110291449165493, 'S12': 0.05847391846673791, 'S13': 0.07697699730257601, 'S14': 0.019435421848891948}\n",
      "State S10, Action S1 -> Transition Probabilities: {'S1': 0.05627993277061539, 'S2': 0.09778324863119114, 'S3': 0.0025782942394727395, 'S4': 0.03770789356805385, 'S5': 0.11414280181527962, 'S6': 0.14476829707346495, 'S7': 0.05065882097742339, 'S8': 0.09751868644557993, 'S9': 0.07367099296712211, 'S11': 0.13347448837627596, 'S12': 0.022368362836540808, 'S13': 0.04760366925093699, 'S14': 0.12144451104804312}\n",
      "State S10, Action S6 -> Transition Probabilities: {'S1': 0.019199926838743633, 'S2': 0.09401539486517542, 'S3': 0.04319687759280576, 'S4': 0.03197833015885444, 'S5': 0.14559536075292162, 'S6': 0.1727971712744405, 'S7': 0.012230435935283892, 'S8': 0.15731991755783165, 'S9': 0.027856444924191242, 'S11': 0.1570679151195877, 'S12': 0.08019852960723943, 'S13': 0.0279163972309348, 'S14': 0.030627298141990028}\n",
      "State S10, Action S11 -> Transition Probabilities: {'S1': 0.12926155087161487, 'S2': 0.05492069410419458, 'S3': 0.07055628623543277, 'S4': 0.08042338012108652, 'S5': 0.1577608771921736, 'S6': 0.04416213631647272, 'S7': 0.1288712039543909, 'S8': 0.043465275946993946, 'S9': 0.14615394657333594, 'S11': 0.08493155441707712, 'S12': 0.0066331559786972005, 'S13': 0.023941448925014576, 'S14': 0.02891848936351544}\n",
      "State S11, Action S10 -> Transition Probabilities: {'S1': 0.0744579334273486, 'S2': 0.007900711545511942, 'S3': 0.11433317149634666, 'S4': 0.07791385469985444, 'S5': 0.10059716980641523, 'S6': 0.05631306656687674, 'S7': 0.10329277906357516, 'S8': 0.022105686866406588, 'S9': 0.008956979685355526, 'S10': 0.1257485564238541, 'S12': 0.12975992738089634, 'S13': 0.11112299675846286, 'S14': 0.06749716627909588}\n",
      "State S11, Action S6 -> Transition Probabilities: {'S1': 0.03720606933989401, 'S2': 0.05496239347839453, 'S3': 0.07565925969883273, 'S4': 0.021081559705358997, 'S5': 0.1348546823135993, 'S6': 0.04316741541063651, 'S7': 0.12253384054237747, 'S8': 0.10276413837161798, 'S9': 0.08679941951754921, 'S10': 0.0330386955843978, 'S12': 0.1283262568936925, 'S13': 0.09147839593001657, 'S14': 0.06812787321363252}\n",
      "State S11, Action S2 -> Transition Probabilities: {'S1': 0.03450319563946872, 'S2': 0.0036530727719827094, 'S3': 0.08448180816777336, 'S4': 0.13731907141386665, 'S5': 0.09355062175567264, 'S6': 0.04329623073796961, 'S7': 0.091801909378931, 'S8': 0.07277513104809544, 'S9': 0.12065014225353149, 'S10': 0.09079213375446107, 'S12': 0.05716989711967293, 'S13': 0.10010120823577216, 'S14': 0.0699055777228024}\n",
      "State S11, Action S7 -> Transition Probabilities: {'S1': 0.09632098149192041, 'S2': 0.12864566010552353, 'S3': 0.08047254607530599, 'S4': 0.034896149696750145, 'S5': 0.10749506743150843, 'S6': 0.03308130560329091, 'S7': 0.1260436691105257, 'S8': 0.003085004344899965, 'S9': 0.009923794665960765, 'S10': 0.07034863918578918, 'S12': 0.09640252358591819, 'S13': 0.13516698426161614, 'S14': 0.07811767444099067}\n",
      "State S11, Action S12 -> Transition Probabilities: {'S1': 0.08284403892156982, 'S2': 0.03330301858617017, 'S3': 0.12954355105422188, 'S4': 0.10147553353775368, 'S5': 0.00017422607919140163, 'S6': 0.15965062244132017, 'S7': 0.04824231496664424, 'S8': 0.08070329182312967, 'S9': 0.16637168588770704, 'S10': 0.09273018814770978, 'S12': 0.01711548882058026, 'S13': 0.0029738260606303967, 'S14': 0.08487221367337142}\n",
      "State S12, Action S11 -> Transition Probabilities: {'S1': 0.07359903719045346, 'S2': 0.08541942077371745, 'S3': 0.03664292927683267, 'S4': 0.13747266458399582, 'S5': 0.03793780687733016, 'S6': 0.11072831642012114, 'S7': 0.06587477287348101, 'S8': 0.1015594198471457, 'S9': 0.05256731278797394, 'S10': 0.04603563369664171, 'S11': 0.047721761788278895, 'S13': 0.09809009984865427, 'S14': 0.10635082403537377}\n",
      "State S12, Action S7 -> Transition Probabilities: {'S1': 0.008866748595883479, 'S2': 0.03293692036646644, 'S3': 0.1074685841434132, 'S4': 0.05750076672419813, 'S5': 0.07690567312620539, 'S6': 0.07540876485145678, 'S7': 0.10667407354644974, 'S8': 0.1271119084503094, 'S9': 0.07674358374244439, 'S10': 0.1156725381024203, 'S11': 0.1181825021482714, 'S13': 0.03540091091885052, 'S14': 0.06112702528363088}\n",
      "State S12, Action S8 -> Transition Probabilities: {'S1': 0.03984341289466187, 'S2': 0.1218196003653826, 'S3': 0.010113242842330096, 'S4': 0.02187321912415882, 'S5': 0.10635856795693598, 'S6': 0.10582967961618853, 'S7': 0.02346449991532377, 'S8': 0.14352690501198942, 'S9': 0.1355903701340408, 'S10': 0.04943946317812756, 'S11': 0.08858526276906886, 'S13': 0.01996362311816611, 'S14': 0.13359215307362562}\n",
      "State S12, Action S13 -> Transition Probabilities: {'S1': 0.03572911273813196, 'S2': 0.10689086466870121, 'S3': 0.11319163745507027, 'S4': 0.05031782801895433, 'S5': 0.11451082302647923, 'S6': 0.05483638848131179, 'S7': 0.06889327889115801, 'S8': 0.08241055040577258, 'S9': 0.008763265390617576, 'S10': 0.09066397192938071, 'S11': 0.04373856013661353, 'S13': 0.12978118294197935, 'S14': 0.10027253591582953}\n",
      "State S13, Action S12 -> Transition Probabilities: {'S1': 0.10679122235851757, 'S2': 0.10271463243441588, 'S3': 0.07046762683173595, 'S4': 0.037255351897697464, 'S5': 0.00026635451682605754, 'S6': 0.04442877700461093, 'S7': 0.040768642532381986, 'S8': 0.1602510706571863, 'S9': 0.11786641072708381, 'S10': 0.028059925905613306, 'S11': 0.10554625104869807, 'S12': 0.1071007952227332, 'S14': 0.07848293886249949}\n",
      "State S13, Action S8 -> Transition Probabilities: {'S1': 0.052748024524634785, 'S2': 0.028659717432739, 'S3': 0.09673745984088146, 'S4': 0.09301125093450482, 'S5': 0.08760426509271214, 'S6': 0.05647016945401582, 'S7': 0.07991186436369394, 'S8': 0.08097193250238606, 'S9': 0.1329101859202883, 'S10': 0.020111084687239215, 'S11': 0.05793379368483617, 'S12': 0.0959277424581045, 'S14': 0.11700250910396372}\n",
      "State S13, Action S9 -> Transition Probabilities: {'S1': 0.04241265529605575, 'S2': 0.07680386648600425, 'S3': 0.1831802931877964, 'S4': 0.03556484347736762, 'S5': 0.10821384388694359, 'S6': 0.0172824761681005, 'S7': 0.02382886756398207, 'S8': 0.1424562095980423, 'S9': 0.08002450019714667, 'S10': 0.05979225030775556, 'S11': 0.01064763196622963, 'S12': 0.0767216992202574, 'S14': 0.14307086264431818}\n",
      "State S13, Action S14 -> Transition Probabilities: {'S1': 0.023275832123606444, 'S2': 0.14091600418494887, 'S3': 0.15645213074085793, 'S4': 0.03230128899278683, 'S5': 0.059466599603489156, 'S6': 0.04201872610551598, 'S7': 0.1243880175056298, 'S8': 0.051855884319916765, 'S9': 0.10623671947291698, 'S10': 0.029308152015162056, 'S11': 0.09418218911955657, 'S12': 0.061659510298294015, 'S14': 0.07793894551731853}\n",
      "State S14, Action S13 -> Transition Probabilities: {'S1': 0.07966401219706687, 'S2': 0.05959830668294156, 'S3': 0.12308254577966117, 'S4': 0.10694258953953516, 'S5': 0.06318773985610364, 'S6': 0.03227624497039294, 'S7': 0.11778139414184971, 'S8': 0.11392330871787942, 'S9': 0.06427611869615939, 'S10': 0.02974822738293642, 'S11': 0.10043058963963528, 'S12': 0.10493825173686558, 'S13': 0.004150670658972835}\n",
      "State S14, Action S9 -> Transition Probabilities: {'S1': 0.10746789834881486, 'S2': 0.09200612352697578, 'S3': 0.08436589220366922, 'S4': 0.1354926089374958, 'S5': 0.13110415765477915, 'S6': 0.0534436878541131, 'S7': 0.05452987656777398, 'S8': 0.01714600808091349, 'S9': 0.1362240129037209, 'S10': 0.05828105257822775, 'S11': 0.005638643535086457, 'S12': 0.11101193719179633, 'S13': 0.013288100616633226}\n",
      "State S14, Action S5 -> Transition Probabilities: {'S1': 0.13432700648039436, 'S2': 0.1391874197431426, 'S3': 0.06888531136182087, 'S4': 0.08932037064862526, 'S5': 0.07379015471995375, 'S6': 0.07781430249494595, 'S7': 0.1180166097631916, 'S8': 0.01675357610405175, 'S9': 0.05130486774837865, 'S10': 0.1131023022240278, 'S11': 0.05584441269319869, 'S12': 0.043736409075441844, 'S13': 0.017917256942826906}\n",
      "Optimal Route: ['S1', np.str_('S12'), np.str_('S4'), np.str_('S9'), np.str_('S6'), np.str_('S11'), np.str_('S7'), np.str_('S5'), np.str_('S7'), np.str_('S2'), np.str_('S6'), np.str_('S7'), np.str_('S1'), np.str_('S11'), np.str_('S12'), np.str_('S1'), np.str_('S10'), np.str_('S13'), np.str_('S3'), np.str_('S9'), np.str_('S12'), np.str_('S14')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RoutePlannerMDP:\n",
    "    def __init__(self, states, actions, transition_probabilities, rewards, gamma=0.9):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.P = transition_probabilities\n",
    "        self.R = rewards  # rewards is now a dictionary of dictionaries\n",
    "        self.gamma = gamma\n",
    "        self.policy = {s: np.random.choice(actions[s]) for s in states}\n",
    "\n",
    "    def value_iteration(self, theta=1e-6):\n",
    "        V = {s: 0 for s in self.states}\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for s in self.states:\n",
    "                v = V[s]\n",
    "                max_value = float('-inf')\n",
    "                for a in self.actions[s]:\n",
    "                    action_value = sum(self.P[s][a][s_next] *\n",
    "                                       (self.R[s][a] + self.gamma * V[s_next])\n",
    "                                       for s_next in self.P[s][a])\n",
    "                    max_value = max(max_value, action_value)\n",
    "                V[s] = max_value\n",
    "                delta = max(delta, abs(v - V[s]))\n",
    "            if delta < theta:\n",
    "                break\n",
    "\n",
    "        for s in self.states:\n",
    "            best_action = None\n",
    "            best_value = float('-inf')\n",
    "            for a in self.actions[s]:\n",
    "                action_value = sum(self.P[s][a][s_next] *\n",
    "                                   (self.R[s][a] + self.gamma * V[s_next])\n",
    "                                   for s_next in self.P[s][a])\n",
    "                if action_value > best_value:\n",
    "                    best_value = action_value\n",
    "                    best_action = a\n",
    "            self.policy[s] = best_action\n",
    "\n",
    "\n",
    "    def get_optimal_route(self, start_state, max_steps=100):\n",
    "        route = [start_state]\n",
    "        current_state = start_state\n",
    "        steps = 0\n",
    "        while current_state != \"S14\" and steps < max_steps:\n",
    "            action = self.policy[current_state]\n",
    "            next_states = list(self.P[current_state][action].keys())\n",
    "            probabilities = list(self.P[current_state][action].values())\n",
    "            current_state = np.random.choice(next_states, p=probabilities)\n",
    "            route.append(current_state)\n",
    "            steps += 1\n",
    "        if current_state != \"S14\":\n",
    "            route.append(\"Max Steps Exceeded\")\n",
    "        return route\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Define states and actions\n",
    "states = [f\"S{i}\" for i in range(1, 15)]\n",
    "\n",
    "actions = {\n",
    "    \"S1\": [\"S2\", \"S6\", \"S10\"],\n",
    "    \"S2\": [\"S1\", \"S6\", \"S7\", \"S3\", \"S11\"],\n",
    "    \"S3\": [\"S2\", \"S7\", \"S8\", \"S4\"],\n",
    "    \"S4\": [\"S3\", \"S8\", \"S9\", \"S5\"],\n",
    "    \"S5\": [\"S4\", \"S9\", \"S14\"],\n",
    "    \"S6\": [\"S1\", \"S2\", \"S10\", \"S11\", \"S7\"],\n",
    "    \"S7\": [\"S2\", \"S3\", \"S8\", \"S12\", \"S11\", \"S6\"],\n",
    "    \"S8\": [\"S3\", \"S4\", \"S7\", \"S9\", \"S12\", \"S13\"],\n",
    "    \"S9\": [\"S4\", \"S5\", \"S8\", \"S13\", \"S14\"],\n",
    "    \"S10\": [\"S1\", \"S6\", \"S11\"],\n",
    "    \"S11\": [\"S10\", \"S6\", \"S2\", \"S7\", \"S12\"],\n",
    "    \"S12\": [\"S11\", \"S7\", \"S8\", \"S13\"],\n",
    "    \"S13\": [\"S12\", \"S8\", \"S9\", \"S14\"],\n",
    "    \"S14\": [\"S13\", \"S9\", \"S5\"]\n",
    "}\n",
    "\n",
    "################################################################################################\n",
    "# Add weather score to states \n",
    "################################################################################################\n",
    "\n",
    "# Weather exposure lookup dictionary\n",
    "weather_exposure = {\n",
    "    (1, 2): 95, (1, 6): 1, (1, 10): 1,\n",
    "    (2, 1): 95, (2, 6): 5, (2, 7): 90, (2, 3): 44, (2, 11): 32,\n",
    "    (3, 2): 44, (3, 7): 57, (3, 8): 9, (3, 4): 41,\n",
    "    (4, 3): 41, (4, 8): 54, (4, 9): 50, (4, 5): 65,\n",
    "    (5, 4): 65, (5, 9): 9, (5, 14): 52,\n",
    "    (6, 1): 1, (6, 2): 5, (6, 10): 27, (6, 11): 50, (6, 7): 82,\n",
    "    (7, 2): 90, (7, 3): 57, (7, 8): 51, (7, 12): 33, (7, 11): 27, (7, 6): 82,\n",
    "    (8, 3): 9, (8, 4): 54, (8, 7): 51, (8, 9): 84, (8, 12): 36, (8, 13): 22,\n",
    "    (9, 4): 50, (9, 5): 9, (9, 8): 84, (9, 13): 31, (9, 14): 39,\n",
    "    (10, 1): 1, (10, 6): 27, (10, 11): 52,\n",
    "    (11, 10): 52, (11, 6): 50, (11, 2): 32, (11, 7): 27, (11, 12): 18,\n",
    "    (12, 11): 18, (12, 7): 33, (12, 8): 36, (12, 13): 46,\n",
    "    (13, 12): 46, (13, 8): 22, (13, 9): 31, (13, 14): 80,\n",
    "    (14, 13): 80, (14, 9): 39, (14, 5): 52\n",
    "}\n",
    "\n",
    "# Assign weather exposure scores for each action\n",
    "weather_scores = {\n",
    "    state: {action: weather_exposure.get((int(state[1:]), int(action[1:])), 1000)\n",
    "            for action in neighbors}\n",
    "    for state, neighbors in actions.items()\n",
    "}\n",
    "\n",
    "# O(1) lookup for weather score\n",
    "# define the state and action to retrieve the weather score\n",
    "state, action = \"S3\", \"S8\"\n",
    "weather_score = weather_scores[state][action]\n",
    "\n",
    "################################################################################################\n",
    "# Add safety score to states\n",
    "################################################################################################\n",
    "\n",
    "# Safety exposure lookup dictionary\n",
    "safety_exposure = {\n",
    "    (1, 2): 22, (1, 6): 13, (1, 10): 15,\n",
    "    (2, 1): 22, (2, 6): 19, (2, 7): 36, (2, 3): 41, (2,11): 21,\n",
    "    (3, 2): 41, (3, 7): 36, (3, 8): 42, (3, 4): 48,\n",
    "    (4, 3): 48, (4, 8): 42, (4, 9): 62, (4, 5): 66,\n",
    "    (5, 4): 66, (5, 9): 99, (5, 14): 99,\n",
    "    (6, 1): 13, (6, 2): 19, (6, 10): 0, (6, 11): 18, (6, 7): 21,\n",
    "    (7, 2): 36, (7, 3): 36, (7, 8): 38, (7, 12): 39, (7, 11): 18, (7, 6): 21,\n",
    "    (8, 3): 42, (8, 4): 42, (8, 7): 38, (8, 9): 64, (8, 12): 58, (8, 13): 69,\n",
    "    (9, 4): 62, (9, 5): 99, (9, 8): 64, (9, 13): 58, (9, 14): 99,\n",
    "    (10, 1): 15, (10, 6): 0, (10, 11): 1,\n",
    "    (11, 10): 1, (11, 6): 18, (11, 2): 21, (11, 7): 18, (11, 12): 46,\n",
    "    (12, 11): 46, (12, 7): 39, (12, 8): 58, (12, 13): 69,\n",
    "    (13, 12): 69, (13, 8): 69, (13, 9): 58, (13, 14): 99,\n",
    "    (14, 13): 99, (14, 9): 99, (14, 5): 99\n",
    "}\n",
    "\n",
    "# Assign safety scores for each action\n",
    "safety_scores = {\n",
    "    state: {action: safety_exposure.get((int(state[1:]), int(action[1:])), 1000)\n",
    "            for action in neighbors}\n",
    "    for state, neighbors in actions.items()\n",
    "}\n",
    "\n",
    "# O(1) lookup for safety score\n",
    "# define the state and action to retrieve the safety score\n",
    "state, action = \"S3\", \"S8\"\n",
    "safety_score = safety_scores[state][action]\n",
    "\n",
    "################################################################################################\n",
    "# Add travel time score to states\n",
    "################################################################################################\n",
    "\n",
    "# Travel Time lookup dictionary\n",
    "travel_time = {\n",
    "    (1, 2): 20, (1, 6): 80, (1, 10): 100,\n",
    "    (2, 1): 20, (2, 6): 60, (2, 7): 60, (2, 3): 40, (2, 11): 100,\n",
    "    (3, 2): 40, (3, 7): 60, (3, 8): 60, (3, 4): 20,\n",
    "    (4, 3): 20, (4, 8): 60, (4, 9): 60, (4, 5): 20,\n",
    "    (5, 4): 20, (5, 9): 60, (5, 14): 100,\n",
    "    (6, 1): 80, (6, 2): 60, (6, 10): 60, (6, 11): 40, (6, 7): 20,\n",
    "    (7, 2): 60, (7, 3): 60, (7, 8): 20, (7, 12): 60, (7, 11): 60, (7, 6): 20,\n",
    "    (8, 3): 60, (8, 4): 60, (8, 7): 20, (8, 9): 20, (8, 12): 60, (8, 13): 40,\n",
    "    (9, 4): 60, (9, 5): 60, (9, 8): 20, (9, 13): 60, (9, 14): 60,\n",
    "    (10, 1): 100, (10, 6): 60, (10, 11): 20,\n",
    "    (11, 10): 20, (11, 6): 40, (11, 2): 100, (11, 7): 60, (11, 12): 20,\n",
    "    (12, 11): 20, (12, 7): 60, (12, 8): 60, (12, 13): 20,\n",
    "    (13, 12): 20, (13, 8): 40, (13, 9): 60, (13, 14): 20,\n",
    "    (14, 13): 20, (14, 9): 60, (14, 5): 100\n",
    "}\n",
    "\n",
    "# Assign travel time scores for each action\n",
    "travel_time_scores = {\n",
    "    state: {action: travel_time.get((int(state[1:]), int(action[1:])), 1000)\n",
    "            for action in neighbors}\n",
    "    for state, neighbors in actions.items()\n",
    "}\n",
    "\n",
    "# O(1) lookup for travel time score\n",
    "# define the state and action to retrieve the travel time score\n",
    "state, action = \"S3\", \"S8\"\n",
    "travel_time_score = travel_time_scores[state][action]\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# Function to dynamically calculate the reward based on the state and action, using the scores\n",
    "################################################################################################\n",
    "\n",
    "# Define the normalization ranges (assuming max and min possible values for each score type)\n",
    "WEATHER_MAX = 1000\n",
    "SAFETY_MAX = 1000\n",
    "TRAVEL_TIME_MAX = 1000\n",
    "\n",
    "# Define the weights for each score (adjust based on their importance)\n",
    "WEATHER_WEIGHT = 0.3\n",
    "SAFETY_WEIGHT = 0.4\n",
    "TRAVEL_TIME_WEIGHT = 0.3\n",
    "\n",
    "\n",
    "def normalize_score(score, max_score):\n",
    "    \"\"\" Normalize the score based on the maximum score for each category. \"\"\"\n",
    "    return score / max_score\n",
    "\n",
    "\n",
    "def calculate_reward(state, action):\n",
    "    \"\"\" \n",
    "    Smarter reward function that considers normalized scores and weighted importance. \n",
    "    Incorporates dynamic scaling for weather, safety, and travel time.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve individual scores\n",
    "    weather_score = weather_scores[state][action]\n",
    "    safety_score = safety_scores[state][action]\n",
    "    travel_time_score = travel_time_scores[state][action]\n",
    "\n",
    "    # Normalize the scores to be between 0 and 1\n",
    "    normalized_weather = normalize_score(weather_score, WEATHER_MAX)\n",
    "    normalized_safety = normalize_score(safety_score, SAFETY_MAX)\n",
    "    normalized_travel_time = normalize_score(\n",
    "        travel_time_score, TRAVEL_TIME_MAX)\n",
    "\n",
    "    # Calculate weighted sum of normalized scores\n",
    "    total_score = (WEATHER_WEIGHT * normalized_weather +\n",
    "                   SAFETY_WEIGHT * normalized_safety +\n",
    "                   TRAVEL_TIME_WEIGHT * normalized_travel_time)\n",
    "\n",
    "    # Reward is the negative of the total score (since higher scores should be worse)\n",
    "    reward = -1 * total_score\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "# Example usage: calculate reward for state \"S3\" and action \"S8\"\n",
    "state, action = \"S3\", \"S8\"\n",
    "reward = calculate_reward(state, action)\n",
    "print(f\"Reward for state {state} and action {action}: {reward}\")\n",
    "\n",
    "################################################################################################\n",
    "# Fill up the Rewards dictionary\n",
    "################################################################################################\n",
    "\n",
    "# Fill up the Rewards dictionary to make sure it's a dictionary of dictionaries\n",
    "rewards = {\n",
    "    state: {action: calculate_reward(state, action) for action in neighbors}\n",
    "    for state, neighbors in actions.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Print the rewards table in a readable format\n",
    "print(\"Rewards Table:\")\n",
    "print(\n",
    "    \"State -> [Action1, Action2, ..., ActionN] -> [Reward1, Reward2, ..., RewardN]\")\n",
    "\n",
    "for state, neighbors in actions.items():\n",
    "    rewards_for_state = rewards[state]\n",
    "    print(f\"{state} -> {neighbors} -> {rewards_for_state}\")\n",
    "\n",
    "################################################################################################\n",
    "# Implement transition probabilities\n",
    "################################################################################################\n",
    "\n",
    "# Define the transition probabilities for each state-action pair\n",
    "def generate_transition_probability(state, action, states):\n",
    "    # Assuming a random probability for demonstration (this can be customized)\n",
    "    prob_sum = 0\n",
    "    transition_probabilities = {}\n",
    "\n",
    "    # Assigning random probabilities to all possible transitions\n",
    "    for next_state in states:\n",
    "        if next_state != state:\n",
    "            # Generate a random probability between 0 and 1\n",
    "            prob = random.uniform(0, 1)\n",
    "            transition_probabilities[next_state] = prob\n",
    "            prob_sum += prob\n",
    "\n",
    "    # Normalize probabilities to ensure they sum up to 1\n",
    "    for next_state in transition_probabilities:\n",
    "        transition_probabilities[next_state] /= prob_sum\n",
    "\n",
    "    return transition_probabilities\n",
    "\n",
    "\n",
    "# Create transition probabilities for each state-action pair\n",
    "transition_probabilities = {\n",
    "    state: {\n",
    "        action: generate_transition_probability(state, action, actions.keys())\n",
    "        for action in neighbors\n",
    "    }\n",
    "    for state, neighbors in actions.items()\n",
    "}\n",
    "\n",
    "# Print the transition probabilities table for each state-action pair\n",
    "print(\"Transition Probabilities Table:\")\n",
    "for state, neighbors in actions.items():\n",
    "    for action in neighbors:\n",
    "        print(\n",
    "            f\"State {state}, Action {action} -> Transition Probabilities: {transition_probabilities[state][action]}\")\n",
    "        \n",
    "################################################################################################\n",
    "# Implement transition probabilities\n",
    "################################################################################################\n",
    "\n",
    "# Initialize and solve the MDP\n",
    "route_planner = RoutePlannerMDP(\n",
    "    states, actions, transition_probabilities, rewards)\n",
    "route_planner.value_iteration()\n",
    "\n",
    "# Find optimal route from S1\n",
    "optimal_route = route_planner.get_optimal_route(\"S1\")\n",
    "print(\"Optimal Route:\", optimal_route)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
